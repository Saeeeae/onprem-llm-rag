# =============================================================================
# On-Premise LLM & RAG System - Development Docker Compose
# Usage: docker compose -f docker-compose.dev.yml up -d
# DevContainer: Referenced by .devcontainer/devcontainer.json
# =============================================================================

services:
  # =============================================================================
  # PostgreSQL
  # =============================================================================
  postgres:
    image: postgres:16-alpine
    container_name: onprem_dev_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-securepassword}
      POSTGRES_DB: ${POSTGRES_DB:-onprem_llm}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - onprem_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =============================================================================
  # Redis
  # =============================================================================
  redis:
    image: redis:7.2-alpine
    container_name: onprem_dev_redis
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - onprem_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # =============================================================================
  # Qdrant
  # =============================================================================
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: onprem_dev_qdrant
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    networks:
      - onprem_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # GLM-OCR Service - Development (GPU + debugpy)
  # =============================================================================
  ocr_service:
    build:
      context: .
      dockerfile: services/ocr/Dockerfile
      target: development
    container_name: onprem_dev_ocr
    environment:
      - OCR_MODEL=zai-org/GLM-OCR
      - OCR_MODEL_PATH=${OCR_MODEL_PATH:-zai-org/GLM-OCR}
      - OCR_SERVICE_PORT=8001
      - CUDA_VISIBLE_DEVICES=0
      - LOG_LEVEL=DEBUG
    volumes:
      - ${MODEL_CACHE_DIR:-./model_cache}/ocr:/root/.cache/huggingface
      - ./services/ocr/ocr_service.py:/app/ocr_service.py
      - ./shared:/app/shared-src
    ports:
      - "8001:8001"
      - "5679:5679"
    networks:
      - onprem_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # =============================================================================
  # E5 Embedding Service - Development (GPU + debugpy)
  # =============================================================================
  embedding_service:
    build:
      context: .
      dockerfile: services/embedding/Dockerfile
      target: development
    container_name: onprem_dev_embedding
    environment:
      - EMBEDDING_MODEL=intfloat/multilingual-e5-large
      - EMBEDDING_MODEL_PATH=${EMBEDDING_MODEL_PATH:-intfloat/multilingual-e5-large}
      - EMBEDDING_SERVICE_PORT=8002
      - CUDA_VISIBLE_DEVICES=0
      - LOG_LEVEL=DEBUG
    volumes:
      - ${MODEL_CACHE_DIR:-./model_cache}/embedding:/root/.cache/huggingface
      - ./services/embedding/embedding_service.py:/app/embedding_service.py
      - ./shared:/app/shared-src
    ports:
      - "8002:8002"
      - "5680:5680"
    networks:
      - onprem_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # =============================================================================
  # Hybrid Chunking Service - Development (CPU + debugpy)
  # =============================================================================
  chunking_service:
    build:
      context: .
      dockerfile: services/chunking/Dockerfile
      target: development
    container_name: onprem_dev_chunking
    environment:
      - CHUNKING_SERVICE_PORT=8003
      - LOG_LEVEL=DEBUG
    volumes:
      - ./services/chunking/chunking_service.py:/app/chunking_service.py
      - ./shared:/app/shared-src
    ports:
      - "8003:8003"
      - "5681:5681"
    networks:
      - onprem_network

  # =============================================================================
  # BGE Reranker Service - Development (GPU + debugpy)
  # =============================================================================
  reranker_service:
    build:
      context: .
      dockerfile: services/reranker/Dockerfile
      target: development
    container_name: onprem_dev_reranker
    environment:
      - RERANKER_MODEL=BAAI/bge-reranker-v2-m3
      - RERANKER_MODEL_PATH=${RERANKER_MODEL_PATH:-BAAI/bge-reranker-v2-m3}
      - RERANKER_SERVICE_PORT=8004
      - CUDA_VISIBLE_DEVICES=0
      - LOG_LEVEL=DEBUG
    volumes:
      - ${MODEL_CACHE_DIR:-./model_cache}/reranker:/root/.cache/huggingface
      - ./services/reranker/reranker_service.py:/app/reranker_service.py
      - ./shared:/app/shared-src
    ports:
      - "8004:8004"
      - "5682:5682"
    networks:
      - onprem_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # =============================================================================
  # vLLM Service - Development (Lightweight model for fast iteration)
  # =============================================================================
  vllm_service:
    build:
      context: ./vllm
      dockerfile: Dockerfile.1gpu
    container_name: onprem_dev_vllm
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - VLLM_TENSOR_PARALLEL_SIZE=1
      - MODEL_NAME=${MODEL_NAME:-TinyLlama/TinyLlama-1.1B-Chat-v1.0}
      - MODEL_PATH=/models
      - MAX_MODEL_LEN=2048
      - GPU_MEMORY_UTILIZATION=0.70
      - TRUST_REMOTE_CODE=true
      - MAX_NUM_SEQS=32
      - ENABLE_CHUNKED_PREFILL=true
    volumes:
      - ${MODEL_DIR:-/mnt/models}:/models:ro
    ports:
      - "8080:8000"
    networks:
      - onprem_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: "4gb"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # =============================================================================
  # FastAPI Backend - Development (hot-reload + debugpy)
  # =============================================================================
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
      target: development
    container_name: onprem_dev_backend
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --log-level debug
    environment:
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-securepassword}
      - POSTGRES_DB=${POSTGRES_DB:-onprem_llm}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION_NAME=documents
      - VLLM_URL=http://vllm_service:8000
      - OCR_URL=http://ocr_service:8001
      - EMBEDDING_URL=http://embedding_service:8002
      - CHUNKING_URL=http://chunking_service:8003
      - RERANKER_URL=http://reranker_service:8004
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-dev-secret-key-not-for-production}
      - CORS_ORIGINS=http://localhost:3000
      - MAX_CONCURRENT_REQUESTS=50
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
    volumes:
      - ./backend/app:/app/app
      - ./backend/logs:/app/logs
      - ./shared:/app/shared-src
      - .:/workspace
      - ${NAS_MOUNT_PATH:-/mnt/nas}:/mnt/nas:ro
      - embeddings_cache:/root/.cache/huggingface
    ports:
      - "8000:8000"
      - "5678:5678"
    networks:
      - onprem_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy

  # =============================================================================
  # Celery Worker - Development (single worker, debug logging)
  # =============================================================================
  celery_worker:
    build:
      context: .
      dockerfile: worker/Dockerfile
      target: development
    container_name: onprem_dev_celery_worker
    command: celery -A celery_app worker --loglevel=debug --concurrency=1 --pool=solo
    environment:
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-securepassword}
      - POSTGRES_DB=${POSTGRES_DB:-onprem_llm}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION_NAME=documents
      - VLLM_URL=http://vllm_service:8000
      - OCR_URL=http://ocr_service:8001
      - EMBEDDING_URL=http://embedding_service:8002
      - CHUNKING_URL=http://chunking_service:8003
      - RERANKER_URL=http://reranker_service:8004
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      - NAS_MOUNT_PATH=${NAS_MOUNT_PATH:-/mnt/nas}
      - OCR_ENGINE=tesseract
      - TESSERACT_LANG=eng+kor
    volumes:
      - ./worker:/app
      - ./shared:/app/shared-src
      - ${NAS_MOUNT_PATH:-/mnt/nas}:/mnt/nas:rw
      - embeddings_cache:/root/.cache/huggingface
    networks:
      - onprem_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy

  # =============================================================================
  # Celery Beat - Development
  # =============================================================================
  celery_beat:
    build:
      context: .
      dockerfile: worker/Dockerfile
      target: development
    container_name: onprem_dev_celery_beat
    command: celery -A celery_app beat --loglevel=debug
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-securepassword}
      - POSTGRES_DB=${POSTGRES_DB:-onprem_llm}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - NAS_SYNC_SCHEDULE=${NAS_SYNC_SCHEDULE:-0 2 * * *}
    volumes:
      - ./worker:/app
      - beat_schedule:/app/schedule
    networks:
      - onprem_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # =============================================================================
  # Flower - Always active in development
  # =============================================================================
  flower:
    build:
      context: .
      dockerfile: worker/Dockerfile
      target: development
    container_name: onprem_dev_flower
    command: celery -A celery_app flower --port=5555 --broker=redis://redis:6379/0
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - FLOWER_BASIC_AUTH=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin}
    ports:
      - "5555:5555"
    networks:
      - onprem_network
    depends_on:
      redis:
        condition: service_healthy

  # =============================================================================
  # Next.js Frontend - Development (Fast Refresh)
  # =============================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    container_name: onprem_dev_frontend
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_WS_URL=ws://localhost:8000
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
      - ./frontend/package.json:/app/package.json
      - /app/node_modules
      - /app/.next
    ports:
      - "3000:3000"
    networks:
      - onprem_network
    depends_on:
      - backend

# =============================================================================
# Networks
# =============================================================================
networks:
  onprem_network:
    driver: bridge

# =============================================================================
# Volumes
# =============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
  beat_schedule:
    driver: local
  embeddings_cache:
    driver: local
